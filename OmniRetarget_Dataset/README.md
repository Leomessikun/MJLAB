---
language: en
license: mit
task_categories:
- robotics
tags:
- robotics
- motion-retargeting
- reinforcement-learning
- humanoid
- trajectory-optimization
---

# OmniRetarget Dataset: Humanoid Loco-Manipulation & Scene Interaction 

[Paper](https://huggingface.co/papers/2509.26633) | [Project Page](https://omniretarget.github.io)

This dataset contains motion trajectories of a G1 humanoid robot interacting with objects and complex terrains. It was generated by **[OMNIRETARGET](https://omniretarget.github.io/)**, an interaction-preserving data generation engine that produces high-quality, kinematically feasible trajectories free of common artifacts like foot-skating and penetration.

<div align="center">
<video autoplay loop muted controls width="70%">
  <source src="https://huggingface.co/datasets/omniretarget/OmniRetarget_Dataset/resolve/main/assets/teaser.mp4" type="video/mp4">
</video>
</div>

## Dataset Structure

Due to licensing restrictions, we cannot release the retargeted [LAFAN1](https://github.com/ubisoft/ubisoft-laforge-animation-dataset) dataset. However, we will open-source our retargeting code so that users can retarget the data themselves.

| Subset                   | Description                                         | Source Data     | Duration (hours) |
| ------------------------ | --------------------------------------------------- | --------------- | ---------------- |
| `robot-object/`          | Motions of the robot carrying objects. | OMOMO           | 3.0             |
| `robot-terrain/`         | Dynamic motions of the robot climbing challenging terrains. | In-house MoCap  | 0.5              |
| `robot-object-terrain/`  | Motions involving both object and terrain interaction. | In-house MoCap  | 0.5              |
| **Total** |                                                     |                 | **4.0** |

Additionally, the `models/` directory contains all the necessary URDF, SDF, and OBJ assets for visualization. These are not required for loading or training with the trajectory data.

## Data Format

Each `.npz` file contains a single trajectory with two keys:
- **`fps`**: Frames per second.
- **`qpos`**: A NumPy array of shape `[T, D]` representing the system state over `T` timesteps. The vector is structured as follows:
    - **Robot Pose (36D):**
        - Floating Base `[qw, qx, qy, qz, x, y, z]` (7D)
        - Joint Positions (29D)
    - **Object Pose (7D, optional):**
        - `[qw, qx, qy, qz, x, y, z]`
    - The total dimension `D` is 36 for motions without an object, and 43 with an object.

## Quick Usage
```bash
# Clone the repository, install dependencies
git lfs install
git clone https://huggingface.co/datasets/omniretarget/OmniRetarget_Dataset
pip install numpy
```
``` bash
# Load data
import glob, numpy as np
paths = glob.glob("robot-object/*.npz")
with np.load(paths[0]) as data:
    qpos = data["qpos"]  # (T, D)
    fps = float(data["fps"])  # e.g., 30.0
```

## Visualize (optional)
A `visualize.py` script using Drake and Meshcat is provided.
```bash
# Install dependencies
pip install drake

# Set `task` inside the script: "object" | "terrain" | "object-terrain"
python visualize.py
```

## Citation
https://omniretarget.github.io/
```bibtex
@inproceedings{Yang2025OmniRetarget,
  title={OmniRetarget: Interaction-Preserving Data Generation for Humanoid Whole-Body Loco-Manipulation and Scene Interaction},
  author={Yang, Lujie and Huang, Xiaoyu and Wu, Zhen and Kanazawa, Angjoo and Abbeel, Pieter and Sferrazza, Carmelo and Liu, C. Karen and Duan, Rocky and Shi, Guanya},
  booktitle={arXiv},
  year={2025}
}
```